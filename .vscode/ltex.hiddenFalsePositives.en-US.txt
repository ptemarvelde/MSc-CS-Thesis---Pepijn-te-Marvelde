{"rule":"CD_NN","sentence":"^\\QHowever, its focus on two table joins limits its applicability to real-world scenarios.\\E$"}
{"rule":"BUNCH_OF","sentence":"^\\QTVM \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q XGBoost Memory access count Memory buffer reuse ratio Number of time kernel is called Touched memory size Halide \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Vector of handcrafted features multiplied by coefficients computed by Neural Network Total number of allocations made Total number of bytes read Total number of scalar instructions Overview of discussed Machine Learning Optimizers\\E$"}
{"rule":"BUNCH_OF","sentence":"^\\QTVM \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q XGBoost Memory access count Memory buffer reuse ratio Number of time kernel is called Touched memory size Halide \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Vector of handcrafted features multiplied by coefficients computed by Neural Network Total number of allocations made Total number of bytes read Total number of scalar instructions Overview of discussed Machine Learning Optimizers\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QAs Machine Learning Algorithms can be expressed in Linear Algebra (LA) we need to express the Data Integration scenario of an ML use case in terms of Linear Algebra, .i.e., we need to translate the Schema Mappings of an integration scenario to Linear Algebra to allow us to achieve the goal of \"pushing down\" ML to the separate source tables.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Qfor each S[FOR]ForEach[1] #1\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qfor each S[FOR]ForEach[1] #1\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QCost Estimation for Factorized Machine Learning Dr. Rihan Hai Master of Science Pepijn te Marvelde\\E$"}
{"rule":"DOUBLE_PUNCTUATION","sentence":"^\\QI, , declare that this thesis titled, and the work presented in it are my own.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_BEGINNING_RULE","sentence":"^\\QWhere I have quoted from the work of others, the source is always given.\\E$"}
{"rule":"WITH_THE_EXCEPTION_OF","sentence":"^\\QWith the exception of such quotations, this thesis is entirely my own work.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QProc.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q2023 IEEE 39th International Conference on Data Engineering (ICDE)\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWe focus on three complementary lines of work: (1) integrating ML algorithms and languages with existing data systems such as RDBMSs, (2) adapting data management-inspired techniques such as query optimization, partitioning, and compression to new systems that target ML workloads, and (3) combining data management and ML ideas to build systems that improve ML lifecycle-related tasks.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q37th IEEE International Conference on Data Engineering, ICDE 2021, Chania, Greece, April 19-22, 2021\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWe introduce three flavors of this approach: F/FDB computes the cofactors in one pass over the materialized factorized join; Favoids this materialization and intermixes cofactor and join computation; F/SQL expresses this mixture as one SQL query.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QExperiments with commercial, public, and synthetic datasets show that it outperforms MADlib, Python StatsModels, and R, by up to three orders of magnitude.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_BEGINNING_RULE","sentence":"^\\QWe define a parameterization of possible schedules much larger than prior methods and use a variant of beam search to search over it.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWe train the cost model by generating and featurizing hundreds of thousands of random programs and schedules.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QIt produces schedules which are on average almost twice as fast as the existing Halide autoscheduler without autotuning, or more than twice as fast with, and is the first automatic scheduling algorithm to significantly outperform human experts on average.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QPVLDB\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWe present alternative approaches to learn over a join that are easy to implement over existing RDBMSs.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_BEGINNING_RULE","sentence":"^\\QWe study the tradeoff space for all our approaches both analytically and empirically.\\E$"}
{"rule":"DASH_RULE","sentence":"^\\QProceedings of the 2016 International Conference on Management of Data, SIGMOD Conference 2016, San Francisco, CA, USA, June 26 - July 01, 2016\\E$"}
{"rule":"THREE_NN","sentence":"^\\Qdblp computer science bibliography, https://dblp.org\\E$"}
{"rule":"THREE_NN","sentence":"^\\QThe data management community has been working for over a decade on tackling data management-related challenges that arise in ML workloads, and has built several systems for advanced analytics.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\QWe propose a new paradigm for computing batch gradient descent that exploits the factorized computation and representation of the training datasets, a rewriting of the regression objective function that decouples the computation of cofactors of model parameters from their convergence, and the commutativity of cofactor computation with relational union and projection.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\QIn this work, we take a first step towards closing this gap by introducing a new abstraction to enable pairwise feature interactions in multi-table data and present an extensive framework of algebraic rewrite rules for factorized LA operators over feature interactions.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QTo do this in an extensible and efficient manner without costly data copies, Trinity leverages and extends an emerging industrial polyglot compiler and runtime, Oracle's GraalVM.\\E$"}
{"rule":"PASSIVE_VOICE","sentence":"^\\QBut all such prior factorized ML/LA stacks are restricted by their chosen programming language (PL) and runtime environment, limiting their reach in emerging industrial data science environments with many PLs (R, Python, etc.) and even cross-PL analytics workflows.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QRe-implementing Morpheus from scratch in each PL/environment is a massive developability overhead for implementation, testing, and maintenance.\\E$"}
{"rule":"EN_QUOTES","sentence":"^\\QOne class of optimizations called \"factorized ML\" helps reduce ML runtimes over multi-table datasets by pushing ML computations down through joins, avoiding the need to materialize such joins.\\E$"}
{"rule":"TOO_LONG_PARAGRAPH","sentence":"^\\QTPCx-AI's core contributions are a novel unified data set covering structured and unstructured data; a fully scalable data generator that can generate realistic data from GB up to PB scale; and a diverse and representative workload using different data types and algorithms, covering a wide range of aspects of real ML workloads such as data integration, data processing, training, and inference.\\E$"}
{"rule":"ADVERB_OR_HYPHENATED_ADJECTIVE","sentence":"^\\QTPCx-AI's core contributions are a novel unified data set covering structured and unstructured data; a fully scalable data generator that can generate realistic data from GB up to PB scale; and a diverse and representative workload using different data types and algorithms, covering a wide range of aspects of real ML workloads such as data integration, data processing, training, and inference.\\E$"}
{"rule":"PASSIVE_VOICE","sentence":"^\\QMany have been rigorously developed in collaboration between academia and industry, but no existing benchmark is standardized.\\E$"}
{"rule":"EN_COMPOUNDS","sentence":"^\\QWith an ever increasing amount of algorithms, systems, and hardware solutions, it is challenging to identify good deployments even for experts.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\Qhttps://www.worldcat.org/search?qt=l2a q=isbnprice = , condition = Used(Good), timestamp = 2023-08-17\\E$"}
{"rule":"DASH_RULE","sentence":"^\\QTPCx-AI - An Industry Standard Benchmark for Artificial Intelligence and Machine Learning Systems\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Qhttps://www.worldcat.org/search?qt=l2a q=isbnprice = , condition = Used(Good), timestamp = 2023-08-17\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWe study the tradeoff space for all our approaches both analytically and empirically.\\E$"}
{"rule":"TOO_LONG_PARAGRAPH","sentence":"^\\QWe also discuss extensions of all our approaches to multi-table joins as well as to Hive.\\E$"}
{"rule":"PASSIVE_VOICE","sentence":"^\\QHowever, most relational datasets are not stored as single tables due to normalization.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QEnterprise data analytics is a booming area in the data management industry.\\E$"}
{"rule":"PASSIVE_VOICE","sentence":"^\\QThe Thesis Abstract is written here (and usually kept to just this page).\\E$"}
{"rule":"PASSIVE_VOICE","sentence":"^\\QThe page is kept centered vertically so can expand into the blank space above the title too.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\QSystem Model Relevant features Orion \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Analytical cost model (I/O and CPU cost) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Decision Rule Buffer size Input table dimensions Model iterations Morpheus \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Heuristic decision rule Tuple ratio Feature ratio MorpheusFI \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Heuristic decision rule Sparsity Input table dimensions Amalur \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Analytical cost model (FLOPs) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Decision rule Complexity ratio Overview of cost estimators for factorized learning\\E$"}
{"rule":"THREE_NN","sentence":"^\\QIn this section, a selection of existing machine learning optimizers and how they approach the cost estimation problem are reviewed.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QHowever, insights from these optimizers can inform the cost estimation problem addressed in this research.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QDeciding between factorization and materialization is a multidimensional cost optimization problem.\\E$"}
{"rule":"AUXILIARY_DO_WITH_INCORRECT_VERB_FORM","sentence":"^\\QIt also performed well on the TPC-AI use cases, saving of training time over a system without factorized ML and a cost estimator to decide whether to do materialized or factorized computation.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QAs Machine Learning Algorithms can be expressed in Linear Algebra (LA) we need to express the Data Integration scenario of an ML use case in terms of Linear Algebra, .i.e., we need to translate the Schema Mappings of an integration scenario to Linear Algebra to allow us to achieve the goal of \"pushing down\" ML to the separate source tables.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QAs Machine Learning Algorithms can be expressed in Linear Algebra (LA) we need to express the Data Integration scenario of an ML use case in terms of Linear Algebra, .i.e., we need to translate the Schema Mappings of an integration scenario to Linear Algebra to allow us to achieve the goal of “pushing down” ML to the separate source tables.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QAs Machine Learning Algorithms can be expressed in Linear Algebra (LA) we need to express the Data Integration scenario of an ML use case in terms of Linear Algebra, .i.e., we need to translate the Schema Mappings of an integration scenario to Linear Algebra to allow us to achieve the goal of “pushing down” ML to the separate source tables.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QFK Primary Key ML Machine Learning PK Foreign Key (G)NMF (Gaussian)-Non-negative Matrix Factorization FLOP FLoating-point OPeration DI Data Integration LA Linear Algebra\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Entity table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Attribute table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Target table, result of joining tables (materialization) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of rows (samples/tuples) in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of columns (features) in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Sparsity (fraction of 0 values) of \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of base tables \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Tuple ratio (\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Feature ratio (\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q)\\E$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"ENGLISH_WORD_REPEAT_RULE","sentence":"^\\QTuple & feature ratio Ratio of rows/columns from \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Overview of features used in the statistical model.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Tuple ratio \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Ratio of rows/columns from \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Influences the number of redundant operations when computing a model\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Feature ratio \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Ratio of columns from \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Influences the number of redundant operations when computing a model\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Join Type \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q The join type used to join the source tables to the target table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Selectivity \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q The fraction of rows from \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q that are included in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Overview of data related features varied in this study.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Entity table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Attribute table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Target table, result of joining tables (materialization) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of rows (samples/tuples) in table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of columns (features) in table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Sparsity (fraction of 0 values) of table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of base tables \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Tuple ratio (\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Feature ratio (\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Join type of table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Selectivity \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of columns in table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Number of rows in table \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q(G)NMF (Gaussian)-Non-negative Matrix Factorization DI Data Integration F/M Factorized/Materialized FK Primary Key FLOP FLoating-point OPeration LA Linear Algebra ML Machine Learning PK Foreign Key\\E$"}
{"rule":"POSSESSIVE_APOSTROPHE","sentence":"^\\QThe Orders table contains information about the orders made by customers, the schema of this table is \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"POSSESSIVE_APOSTROPHE","sentence":"^\\QThe Orders table contains information about the orders made by customers, the schema of this table is \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"AGREEMENT_SENT_START","sentence":"^\\QThe exact overview of which experiment was run on which machines is shown in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWhen possible Docker containers were used, for the experiments on the DAIC cluster this container was converted to an Apptainer image.\\E$"}
{"rule":"PRP_JJ","sentence":"^\\QFirst we left join \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Next, we inner join the result with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to get the final schema \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q:\\E$"}
{"rule":"PRP_JJ","sentence":"^\\QFirst we left join \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Next, we inner join the result with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to get the final schema \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\QFirst we left join \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Next, we inner join the result with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to get the final schema \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\QIntuitively the materialization process can be seen as: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q For each source table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Map the source table rows to the target table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Map the source table columns to the target table \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Sum the results\\E$"}
{"rule":"TOO_LONG_PARAGRAPH","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\QFor these element-wise operations the transposed rewrite is: \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\QThese rewrite rules are: rowSums \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\QrowSums \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q rowSums \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\QcolSums \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\QThe rewrite rule for left matrix multiplication (LMM) with another matrix \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is: \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\QThe rewrite rule therefore is very simple for these arithmetic operators, as well as for any other scalar function (e.g., \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Qor more generally: \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"BEEN_PART_AGREEMENT","sentence":"^\\QBy plotting programs on such a roofline chart one can reason about whether they are compute- or memory-bound by checking whether it is to the left (memory bound) or to the right of the ridge point's x coordinate (compute bound).\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qpossible time saved.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QNote: the transpose column summation figure should look like the row summation (non transpose) figure.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QThis decision between factorization and materialization is a multidimensional cost optimization problem.\\E$"}
{"rule":"POSSESSIVE_APOSTROPHE","sentence":"^\\QThe Orders table contains information about orders made by customers, the schema of this table is \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QSchema mapping is an integral step in the Data Integration process and thus to Factorized ML.\\E$"}
{"rule":"PRP_JJ","sentence":"^\\QFirst, we left join \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Next, we inner join the result with \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to get the final schema \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q: \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"THREE_NN","sentence":"^\\QAs Machine Learning algorithms can be expressed in Linear Algebra (LA), we need to express the Data Integration scenario of an ML use case in terms of Linear Algebra, .i.e., we need to translate the Schema Mappings of an integration scenario to Linear Algebra to allow us to achieve the goal of “pushing down” ML to the separate source tables.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QAs Machine Learning algorithms can be expressed in Linear Algebra (LA), we need to express the Data Integration scenario of an ML use case in terms of Linear Algebra, .i.e., we need to translate the Schema Mappings of an integration scenario to Linear Algebra to allow us to achieve the goal of “pushing down” ML to the separate source tables.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWe also leave out \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q in the subcalculations for \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q (number of centroids) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Qrand\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Randomly initialize centroids matrix \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\QrowSums(\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q)\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Compute the \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q-norm of points for distances \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\QIn this section we have presented the rewrite rules for the Normalized matrix, for commonly used Linear Algebra operators, and how these are used in the training of Machine Learning models without the need to explicitly compute the join between the source tables.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\QThe decision rule considers the number of base tables, the number of sparse dimension tables, and the sparsity of each dimension table, it states that factorization should be undertaken only when a low ratio of the base tables is sparse, or if the ratio is high and the sparsity of each base table times the ratio of the number of samples in S to the number of rows in R is greater than 1.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QIn the next section the collected profiling metrics are aggregated and analyzed, giving insight into how GPU intrinsics can affect the trade-off.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\QNumber of Streaming Processors Number of compute cores, clock speeds and floating point processing power Cache characteristics (L1, L2 size & bandwidth) Memory characteristics (bandwidth, frequency) GPU architecture The specific values for these variables, along with the exact types of GPU used, are provided in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QBy conducting micro-benchmarks within a representative subrange of our independent variables, we discern how these variables influence the execution of computations on the GPU.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q[Feature importances of the hybrid model]Feature importances of the Hybrid model, XGBoost (GPU) leg.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QWe have explored the cost estimation landscape for factorized machine learning, with a particular focus on the performance of GPUs compared to CPUs.\\E$"}
{"rule":"OTHER_OTHERS","sentence":"^\\QInitially developed to assess inner join scenarios, certain rows from various source tables were excluded to accommodate other join types.\\E$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\QTime Saved\\E$"}
